{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bản bám sát giáo trình, không dùng các kỹ thuật hiện đại như adam optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.126643Z",
     "iopub.status.busy": "2025-12-05T11:29:33.126253Z",
     "iopub.status.idle": "2025-12-05T11:29:33.131485Z",
     "shell.execute_reply": "2025-12-05T11:29:33.130603Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.126617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.133178Z",
     "iopub.status.busy": "2025-12-05T11:29:33.132734Z",
     "iopub.status.idle": "2025-12-05T11:29:33.147472Z",
     "shell.execute_reply": "2025-12-05T11:29:33.146635Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.133151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_idx_images(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num, rows * cols)\n",
    "    return images\n",
    "\n",
    "def load_idx_labels(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.149138Z",
     "iopub.status.busy": "2025-12-05T11:29:33.148809Z",
     "iopub.status.idle": "2025-12-05T11:29:33.291495Z",
     "shell.execute_reply": "2025-12-05T11:29:33.290623Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.149119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/kaggle/input/mnist-dataset\"\n",
    "\n",
    "X_train = load_idx_images(DATA_PATH + \"/train-images.idx3-ubyte\")\n",
    "y_train = load_idx_labels(DATA_PATH + \"/train-labels.idx1-ubyte\")\n",
    "\n",
    "X_test = load_idx_images(DATA_PATH + \"/t10k-images.idx3-ubyte\")\n",
    "y_test = load_idx_labels(DATA_PATH + \"/t10k-labels.idx1-ubyte\")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.292722Z",
     "iopub.status.busy": "2025-12-05T11:29:33.292400Z",
     "iopub.status.idle": "2025-12-05T11:29:33.345728Z",
     "shell.execute_reply": "2025-12-05T11:29:33.344815Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.292697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.347925Z",
     "iopub.status.busy": "2025-12-05T11:29:33.347629Z",
     "iopub.status.idle": "2025-12-05T11:29:33.353303Z",
     "shell.execute_reply": "2025-12-05T11:29:33.352596Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.347905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def raw_pixel_features(X):\n",
    "    return X / 255.0\n",
    "\n",
    "def pca_features(X_train, X_val, n_components=50):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "    return X_train_pca, X_val_pca\n",
    "\n",
    "def hog_like_features(X):\n",
    "    X = X.reshape(-1, 28, 28)\n",
    "    gx = np.diff(X, axis=2)\n",
    "    gy = np.diff(X, axis=1)\n",
    "\n",
    "    gx = gx.reshape(X.shape[0], -1)\n",
    "    gy = gy.reshape(X.shape[0], -1)\n",
    "\n",
    "    return np.concatenate([gx, gy], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.354250Z",
     "iopub.status.busy": "2025-12-05T11:29:33.354034Z",
     "iopub.status.idle": "2025-12-05T11:29:33.368863Z",
     "shell.execute_reply": "2025-12-05T11:29:33.368024Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.354232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_val, y_val, title=\"Model\"):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred, digits=4)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {title}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.370064Z",
     "iopub.status.busy": "2025-12-05T11:29:33.369812Z",
     "iopub.status.idle": "2025-12-05T11:29:33.456814Z",
     "shell.execute_reply": "2025-12-05T11:29:33.455906Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.370043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SoftmaxRegression:\n",
    "    \"\"\"\n",
    "    Softmax Regression - Academic Report Ready Version\n",
    "    ---------------------------------------------------\n",
    "    - Mini-batch SGD\n",
    "    - Softmax + Cross-Entropy (Sparse)\n",
    "    - Correct L2 Regularization\n",
    "    - Xavier Initialization\n",
    "    - Z-score Normalization\n",
    "    - Fully consistent with mathematical formulation\n",
    "    - Numerical Gradient Checking\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=0.1,\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        reg=1e-4,\n",
    "        normalize=True,\n",
    "        random_state=None,\n",
    "        verbose=True\n",
    "    ):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.reg = reg\n",
    "        self.normalize = normalize\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.scaler_mean = None\n",
    "        self.scaler_std = None\n",
    "        self.history = {\"loss\": []}\n",
    "        self.n_samples = None\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "    # =========================\n",
    "    # Initialization\n",
    "    # =========================\n",
    "    def _initialize_weights(self, n_features, n_classes):\n",
    "        std = np.sqrt(1.0 / n_features)\n",
    "        self.W = np.random.randn(n_features, n_classes) * std\n",
    "        self.b = np.zeros((1, n_classes))\n",
    "\n",
    "    # =========================\n",
    "    # Core Math\n",
    "    # =========================\n",
    "    def _softmax(self, z):\n",
    "        z_max = np.max(z, axis=1, keepdims=True)\n",
    "        exp_z = np.exp(z - z_max)\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def _one_hot(self, y, n_classes):\n",
    "        oh = np.zeros((y.shape[0], n_classes))\n",
    "        oh[np.arange(y.shape[0]), y] = 1.0\n",
    "        return oh\n",
    "\n",
    "    def _forward(self, X):\n",
    "        return np.dot(X, self.W) + self.b\n",
    "\n",
    "    def _loss_and_gradients(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        scores = self._forward(X)\n",
    "        probs = self._softmax(scores)\n",
    "\n",
    "        correct_logprobs = -np.log(probs[np.arange(m), y] + 1e-12)\n",
    "        data_loss = np.mean(correct_logprobs)\n",
    "\n",
    "        reg_loss = (self.reg / (2 * self.n_samples)) * np.sum(self.W ** 2)\n",
    "        loss = data_loss + reg_loss\n",
    "\n",
    "        Y = self._one_hot(y, probs.shape[1])\n",
    "        diff = probs - Y\n",
    "\n",
    "        dW = (np.dot(X.T, diff) / m) + (self.reg / self.n_samples) * self.W\n",
    "        db = np.sum(diff, axis=0, keepdims=True) / m\n",
    "\n",
    "        return loss, dW, db\n",
    "\n",
    "    # =========================\n",
    "    # Training\n",
    "    # =========================\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=int)\n",
    "\n",
    "        if self.normalize:\n",
    "            self.scaler_mean = X.mean(axis=0)\n",
    "            self.scaler_std = X.std(axis=0)\n",
    "            self.scaler_std[self.scaler_std == 0] = 1.0\n",
    "            X = (X - self.scaler_mean) / self.scaler_std\n",
    "\n",
    "        self.n_samples, n_features = X.shape\n",
    "        n_classes = int(np.max(y)) + 1\n",
    "\n",
    "        self._initialize_weights(n_features, n_classes)\n",
    "\n",
    "        num_batches = int(np.ceil(self.n_samples / self.batch_size))\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            idx = np.random.permutation(self.n_samples)\n",
    "            X_shuf, y_shuf = X[idx], y[idx]\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "            for i in range(num_batches):\n",
    "                start = i * self.batch_size\n",
    "                end = min((i + 1) * self.batch_size, self.n_samples)\n",
    "\n",
    "                X_batch = X_shuf[start:end]\n",
    "                y_batch = y_shuf[start:end]\n",
    "\n",
    "                loss, dW, db = self._loss_and_gradients(X_batch, y_batch)\n",
    "\n",
    "                self.W -= self.learning_rate * dW\n",
    "                self.b -= self.learning_rate * db\n",
    "\n",
    "                epoch_loss += loss * (end - start)\n",
    "\n",
    "            epoch_loss /= self.n_samples\n",
    "            self.history[\"loss\"].append(epoch_loss)\n",
    "\n",
    "            if self.verbose and ((epoch == 0) or ((epoch + 1) % 10 == 0)):\n",
    "                print(f\"Epoch {epoch+1}/{self.epochs} | Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    # =========================\n",
    "    # Prediction\n",
    "    # =========================\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        if self.normalize:\n",
    "            X = (X - self.scaler_mean) / self.scaler_std\n",
    "        scores = self._forward(X)\n",
    "        return self._softmax(scores)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n",
    "\n",
    "    # =========================\n",
    "    # Numerical Gradient Check\n",
    "    # =========================\n",
    "    def gradient_check(self, X, y, eps=1e-5, tol=1e-6):\n",
    "        X = X[:5]\n",
    "        y = y[:5]\n",
    "\n",
    "        if self.normalize:\n",
    "            mu = X.mean(axis=0)\n",
    "            std = X.std(axis=0)\n",
    "            std[std == 0] = 1.0\n",
    "            X = (X - mu) / std\n",
    "\n",
    "        self.n_samples, n_features = X.shape\n",
    "        n_classes = int(np.max(y)) + 1\n",
    "\n",
    "        self._initialize_weights(n_features, n_classes)\n",
    "\n",
    "        _, dW_anal, db_anal = self._loss_and_gradients(X, y)\n",
    "\n",
    "        num_dW = np.zeros_like(self.W)\n",
    "        for i in range(n_features):\n",
    "            for j in range(n_classes):\n",
    "                old = self.W[i, j]\n",
    "\n",
    "                self.W[i, j] = old + eps\n",
    "                loss1, _, _ = self._loss_and_gradients(X, y)\n",
    "\n",
    "                self.W[i, j] = old - eps\n",
    "                loss2, _, _ = self._loss_and_gradients(X, y)\n",
    "\n",
    "                num_dW[i, j] = (loss1 - loss2) / (2 * eps)\n",
    "                self.W[i, j] = old\n",
    "\n",
    "        num_db = np.zeros_like(self.b)\n",
    "        for j in range(n_classes):\n",
    "            old = self.b[0, j]\n",
    "\n",
    "            self.b[0, j] = old + eps\n",
    "            loss1, _, _ = self._loss_and_gradients(X, y)\n",
    "\n",
    "            self.b[0, j] = old - eps\n",
    "            loss2, _, _ = self._loss_and_gradients(X, y)\n",
    "\n",
    "            num_db[0, j] = (loss1 - loss2) / (2 * eps)\n",
    "            self.b[0, j] = old\n",
    "\n",
    "        def rel_error(a, b):\n",
    "            return np.max(np.abs(a - b) / (np.maximum(1e-8, np.abs(a) + np.abs(b))))\n",
    "\n",
    "        err_W = rel_error(dW_anal, num_dW)\n",
    "        err_b = rel_error(db_anal, num_db)\n",
    "\n",
    "        print(f\"Gradient check | rel_err(W)={err_W:.2e}, rel_err(b)={err_b:.2e}\")\n",
    "        return err_W < tol and err_b < tol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:33.458039Z",
     "iopub.status.busy": "2025-12-05T11:29:33.457771Z",
     "iopub.status.idle": "2025-12-05T11:29:46.481436Z",
     "shell.execute_reply": "2025-12-05T11:29:46.480654Z",
     "shell.execute_reply.started": "2025-12-05T11:29:33.458013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Xtr_raw = raw_pixel_features(X_train)\n",
    "Xval_raw = raw_pixel_features(X_val)\n",
    "\n",
    "model_raw = SoftmaxRegression(\n",
    "    learning_rate=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    reg=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "acc_raw = evaluate_model(\n",
    "    model_raw, Xtr_raw, y_train, Xval_raw, y_val,\n",
    "    title=\"Softmax - Raw Pixels (784D)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:46.482459Z",
     "iopub.status.busy": "2025-12-05T11:29:46.482214Z",
     "iopub.status.idle": "2025-12-05T11:29:53.421183Z",
     "shell.execute_reply": "2025-12-05T11:29:53.420492Z",
     "shell.execute_reply.started": "2025-12-05T11:29:46.482440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Xtr_pca, Xval_pca = pca_features(Xtr_raw, Xval_raw, n_components=50)\n",
    "\n",
    "model_pca = SoftmaxRegression(\n",
    "    learning_rate=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    reg=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "acc_pca = evaluate_model(\n",
    "    model_pca, Xtr_pca, y_train, Xval_pca, y_val,\n",
    "    title=\"Softmax - PCA (50D)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:29:53.422183Z",
     "iopub.status.busy": "2025-12-05T11:29:53.421959Z",
     "iopub.status.idle": "2025-12-05T11:30:19.201083Z",
     "shell.execute_reply": "2025-12-05T11:30:19.200383Z",
     "shell.execute_reply.started": "2025-12-05T11:29:53.422161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Xtr_hog = hog_like_features(X_train)\n",
    "Xval_hog = hog_like_features(X_val)\n",
    "\n",
    "model_hog = SoftmaxRegression(\n",
    "    learning_rate=0.05,\n",
    "    epochs=60,\n",
    "    batch_size=128,\n",
    "    reg=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "acc_hog = evaluate_model(\n",
    "    model_hog, Xtr_hog, y_train, Xval_hog, y_val,\n",
    "    title=\"Softmax - HOG-like Features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:30:19.203441Z",
     "iopub.status.busy": "2025-12-05T11:30:19.203190Z",
     "iopub.status.idle": "2025-12-05T11:30:19.212147Z",
     "shell.execute_reply": "2025-12-05T11:30:19.211530Z",
     "shell.execute_reply.started": "2025-12-05T11:30:19.203422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Feature Type\": [\"Raw Pixels (784D)\", \"PCA (50D)\", \"HOG-like\"],\n",
    "    \"Accuracy\": [acc_raw, acc_pca, acc_hog]\n",
    "})\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:30:19.213219Z",
     "iopub.status.busy": "2025-12-05T11:30:19.212984Z",
     "iopub.status.idle": "2025-12-05T11:30:19.361620Z",
     "shell.execute_reply": "2025-12-05T11:30:19.360853Z",
     "shell.execute_reply.started": "2025-12-05T11:30:19.213196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(results[\"Feature Type\"], results[\"Accuracy\"])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Softmax Regression Performance Comparison\")\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 102285,
     "sourceId": 242592,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "virenv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
